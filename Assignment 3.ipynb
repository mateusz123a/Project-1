{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load mlmc.py\n",
    "import numpy\n",
    "import numpy.linalg\n",
    "\n",
    "class WeakConvergenceFailure(Exception):\n",
    "    pass\n",
    "\n",
    "def mlmc(Lmin, Lmax, N0, eps, mlmc_fn, alpha_0, beta_0, gamma):\n",
    "    \"\"\"\n",
    "    Multi-level Monte Carlo estimation.\n",
    "\n",
    "    (P, Nl) = mlmc(...)\n",
    "\n",
    "    Outputs:\n",
    "      P:  value\n",
    "      Nl: number of samples on each level\n",
    "    Inputs:\n",
    "      Lmin: minimum level of refinement  >= 2\n",
    "      Lmax: maximum level of refinement  >= Lmin\n",
    "      N0:   initial number of samples    >  0\n",
    "      eps:  desired accuracy (rms error) >  0\n",
    "\n",
    "      alpha: weak error is  O(2^{-alpha*l})\n",
    "      beta:  variance is    O(2^{-beta*l})\n",
    "      gamma: sample cost is O(2^{gamma*l})  > 0\n",
    "\n",
    "      If alpha, beta are not positive then they will be estimated.\n",
    "\n",
    "      mlmc_fn: the user low-level routine. Its interface is\n",
    "        sums = mlmc_fn(l, N)\n",
    "      with inputs\n",
    "        l = level\n",
    "        N = number of paths\n",
    "      and a numpy array of outputs\n",
    "        sums[0] = sum(Y)\n",
    "        sums[1] = sum(Y**2)\n",
    "      where Y are iid samples with expected value\n",
    "        E[P_0]            on level 0\n",
    "        E[P_l - P_{l-1}]  on level l > 0\n",
    "    \"\"\"\n",
    "\n",
    "    # Check arguments\n",
    "\n",
    "    if Lmin < 2:\n",
    "        raise ValueError(\"Need Lmin >= 2\")\n",
    "    if Lmax < Lmin:\n",
    "        raise ValueError(\"Need Lmax >= Lmin\")\n",
    "    if N0 <= 0 or eps <= 0 or gamma <= 0:\n",
    "        raise ValueError(\"Need N0 > 0, eps > 0, gamma > 0\")\n",
    "\n",
    "    # Initialisation\n",
    "\n",
    "    alpha = max(0, alpha_0)\n",
    "    beta  = max(0, beta_0)\n",
    "\n",
    "    theta = 0.25\n",
    "\n",
    "    L = Lmin\n",
    "\n",
    "    Nl   = numpy.zeros(L+1)\n",
    "    suml = numpy.zeros((2, L+1))\n",
    "    dNl  = N0*numpy.ones(L+1)\n",
    "\n",
    "    while sum(dNl) > 0:\n",
    "\n",
    "        # update sample sums\n",
    "\n",
    "        for l in range(0, L+1):\n",
    "            if dNl[l] > 0:\n",
    "                sums       = mlmc_fn(l, int(dNl[l]))\n",
    "                Nl[l]      = Nl[l] + dNl[l]\n",
    "                suml[0, l] = suml[0, l] + sums[0]\n",
    "                suml[1, l] = suml[1, l] + sums[1]\n",
    "\n",
    "        # compute absolute average and variance\n",
    "\n",
    "        ml = numpy.abs(       suml[0, :]/Nl)\n",
    "        Vl = numpy.maximum(0, suml[1, :]/Nl - ml**2)\n",
    "\n",
    "        # fix to cope with possible zero values for ml and Vl\n",
    "        # (can happen in some applications when there are few samples)\n",
    "\n",
    "        for l in range(3, L+2):\n",
    "            ml[l-1] = max(ml[l-1], 0.5*ml[l-2]/2**alpha)\n",
    "            Vl[l-1] = max(Vl[l-1], 0.5*Vl[l-2]/2**beta)\n",
    "\n",
    "        # use linear regression to estimate alpha, beta if not given\n",
    "        if alpha_0 <= 0:\n",
    "            A = numpy.ones((L, 2)); A[:, 0] = range(1, L+1)\n",
    "            x = numpy.linalg.solve(A, numpy.log2(ml[1:]))\n",
    "            alpha = max(0.5, -x[0])\n",
    "\n",
    "        if beta_0 <= 0:\n",
    "            A = numpy.ones((L, 2)); A[:, 0] = range(1, L+1)\n",
    "            x = numpy.linalg.solve(A, numpy.log2(Vl[1:]))\n",
    "            beta = max(0.5, -x[0])\n",
    "\n",
    "        # set optimal number of additional samples\n",
    "\n",
    "        Cl = 2**(gamma*numpy.arange(0, L+1))\n",
    "        Ns = numpy.ceil( numpy.sqrt(Vl/Cl) * sum(numpy.sqrt(Vl*Cl)) / ((1-theta)*eps**2) )\n",
    "        dNl = numpy.maximum(0, Ns-Nl)\n",
    "\n",
    "        # if (almost) converged, estimate remaining error and decide\n",
    "        # whether a new level is required\n",
    "\n",
    "        if sum(dNl > 0.01*Nl) == 0:\n",
    "            rem = ml[L] / (2.0**alpha - 1.0)\n",
    "\n",
    "            if rem > numpy.sqrt(theta)*eps:\n",
    "                if L == Lmax:\n",
    "                    raise WeakConvergenceFailure(\"Failed to achieve weak convergence\")\n",
    "                else:\n",
    "                    L = L + 1\n",
    "                    Vl = numpy.append(Vl, Vl[-1] / 2.0**beta)\n",
    "                    Nl = numpy.append(Nl, 0.0)\n",
    "                    suml = numpy.column_stack([suml, [0, 0]])\n",
    "\n",
    "                    Cl = 2**(gamma*numpy.arange(0, L+1))\n",
    "                    Ns = numpy.ceil( numpy.sqrt(Vl/Cl) * sum(numpy.sqrt(Vl*Cl)) / ((1-theta)*eps**2) )\n",
    "                    dNl = numpy.maximum(0, Ns-Nl)\n",
    "\n",
    "    # finally, evaluate the multilevel estimator\n",
    "    P = sum(suml[0,:]/Nl)\n",
    "\n",
    "    return (P, Nl)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gene Transcription Model\n",
    "\n",
    "\\begin{align*}\n",
    "G &\\xrightarrow[]{25} G + 25 \\\\\n",
    "M &\\xrightarrow[]{1000} M + P \\\\\n",
    "P + P & \\xrightarrow[]{0.001} D \\\\\n",
    "M &\\xrightarrow[]{0.1} \\emptyset \\\\\n",
    "P &\\xrightarrow[]{1} \\emptyset\n",
    "\\end{align*}\n",
    "\n",
    "We gather the quantities into a vector\n",
    "$$ X_t = \\begin{pmatrix}\n",
    "\\text{# of $M$ molecues at time $t$} \\\\\n",
    "\\text{# of $P$ molecues at time $t$} \\\\\n",
    "\\text{# of $D$ molecues at time $t$}\n",
    "\\end{pmatrix} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3587.27987654321, array([162., 100., 100.,   2.]))"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "class Reaction(object):\n",
    "    def __init__(self, reactants, products, ease):\n",
    "        \"\"\"\n",
    "        reactants and products should be a list of integers\n",
    "        \"\"\"\n",
    "        self.reactants = reactants\n",
    "        self.products = products\n",
    "        self.change = np.array(products) - np.array(reactants)\n",
    "        self.ease = ease\n",
    "        \n",
    "    def rate(self, molecular_counts):\n",
    "        \"\"\"\n",
    "        molecular_counts[n, k] should give the number of molecules of\n",
    "        type k in the nth path. Returns rates such that rates[n] is the rate\n",
    "        this reaction in the nth path.\n",
    "        \"\"\"\n",
    "        N, _ = molecular_counts.shape\n",
    "        rate = self.ease * np.ones(N)\n",
    "        \n",
    "        for reactant, amount in enumerate(self.reactants):\n",
    "            for i in range(amount):\n",
    "                rate = rate * (molecular_counts[:,reactant] - i)\n",
    "        \n",
    "        return rate\n",
    "\n",
    "def calculate_rates(reactions, paths):\n",
    "    \"\"\"\n",
    "    reactions: a list of R reactions\n",
    "    paths: a N * K array, paths[n, i] is the number of molecules of type i in path n\n",
    "    \n",
    "    returns a N * R array rates[n, j] is the rate of reaction j in path n\n",
    "    \"\"\"\n",
    "    return np.array([reaction.rate(paths) for reaction in reactions]).T\n",
    "\n",
    "def tau_leaping_mlmc(reactions, initial_counts, T, n0, M, N, l):\n",
    "    \"\"\"\n",
    "    reactions: a list of reactions of class Reaction\n",
    "    initial_counts: a R array of initial molecule\n",
    "    T: final time\n",
    "    n0: number of steps in layer 0\n",
    "    M: refinement factor\n",
    "    N: total number of paths to use\n",
    "    l: level for MLMC\n",
    "    \n",
    "    return sums, an array with 2 entries, sums[0] is the sum of estimators,\n",
    "    sums[1] is the sum of the square estimators\n",
    "    \"\"\"\n",
    "    max_paths_per_loop = 1000\n",
    "    \n",
    "    R = initial_counts.size # number of reactants\n",
    "    changes = np.array([reaction.change for reaction in reactions])\n",
    "    # changes[i, j] would give the change in numbers of molecule j in the ith reaction\n",
    "    \n",
    "    n = n0 * (M ** l)\n",
    "    h = T / n\n",
    "    \n",
    "    sums = np.zeros((2, R))\n",
    "    \n",
    "    for N0 in range(0, N, max_paths_per_loop):\n",
    "        N1 = min(max_paths_per_loop, N - N0) # number of paths this loop will use\n",
    "\n",
    "        if l == 0:\n",
    "            X_f = initial_counts * np.ones((N1, R)) # molecular counts\n",
    "            X_c = np.zeros((N1, R)) # course count is just 0 for the lowest level\n",
    "\n",
    "            for _ in range(n):\n",
    "                rates = calculate_rates(reactions, X_f)\n",
    "                reactions_occured = np.random.poisson(h * rates)\n",
    "                X_f += reactions_occured @ changes\n",
    "                X_f = np.maximum(X_f, 0) # to handle negative molecular counts\n",
    "        \n",
    "        if l >= 1:\n",
    "            X_c = initial_counts * np.ones((N1, R)) # coarse path molecular counts\n",
    "            X_f = initial_counts * np.ones((N1, R)) # fine path molecular counts\n",
    "            \n",
    "            for i in range(n):\n",
    "                rates_f = calculate_rates(reactions, X_f)\n",
    "                if i % M == 0:\n",
    "                    rates_c = calculate_rates(reactions, X_c) # update coarse rates only every m steps\n",
    "                \n",
    "                R_abs = np.random.poisson(h * np.abs(rates_f - rates_c))\n",
    "                R_min = np.random.poisson(h * np.minimum(rates_f, rates_c))\n",
    "\n",
    "                R_f = R_min + np.where(rates_f > rates_c, R_abs, 0)\n",
    "                R_c = R_min + np.where(rates_c > rates_f, R_abs, 0)\n",
    "                \n",
    "                X_f += R_f @ changes\n",
    "                X_c += R_c @ changes\n",
    "                \n",
    "                X_f = np.maximum(X_f, 0)\n",
    "                X_c = np.maximum(X_c, 0)\n",
    "                \n",
    "        diff = X_f - X_c\n",
    "        sums += np.array([diff, diff**2]).sum(axis=1)\n",
    "         \n",
    "    return np.array(sums)\n",
    "\n",
    "reactions = [([1, 0, 0, 0], [1, 1, 0, 0], 25),\n",
    "             ([0, 1, 0, 0], [0, 1, 1, 0], 1000),\n",
    "             ([0, 0, 2, 0], [0, 0, 0, 1], 0.001),\n",
    "             ([0, 1, 0, 0], [0, 0, 0, 0], 0.1),\n",
    "             ([0, 0, 1, 0], [0, 0, 0, 0], 1)]\n",
    "\n",
    "reactions = [Reaction(*reaction) for reaction in reactions]\n",
    "\n",
    "T = 1 # terminal time\n",
    "n0 = 9 # initial number of time steps\n",
    "initial_counts = np.array([1, 0, 0, 0])\n",
    "M = 3 # refinement factor\n",
    "Lmin = 2\n",
    "Lmax = 100\n",
    "N0 = 100\n",
    "eps = 100\n",
    "alpha = np.log2(M)\n",
    "beta = np.log2(M)\n",
    "gamma = np.log2(M)\n",
    "\n",
    "def mlmc_fn(l, N):\n",
    "    \"\"\"a wrapper for the tau_leaping_mlmc method\"\"\"\n",
    "    return tau_leaping_mlmc(reactions, initial_counts, T, n0, M, N, l)[:,-1]\n",
    "\n",
    "mlmc(Lmin, Lmax, N0, eps, mlmc_fn, alpha, beta, gamma)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
