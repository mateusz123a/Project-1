{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Preliminaries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "In this section, we gather the code provided to us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# %load mlmc.py\n",
    "import numpy as np\n",
    "import numpy.linalg\n",
    "import numpy.random as rd\n",
    "import timeit\n",
    "import sys\n",
    "from math import sqrt\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class WeakConvergenceFailure(Exception):\n",
    "    pass\n",
    "\n",
    "def mlmc(Lmin, Lmax, N0, eps, mlmc_fn, alpha_0, beta_0, gamma):\n",
    "    \"\"\"\n",
    "    Multi-level Monte Carlo estimation.\n",
    "\n",
    "    (P, Nl) = mlmc(...)\n",
    "\n",
    "    Outputs:\n",
    "      P:  value\n",
    "      Nl: number of samples on each level\n",
    "    Inputs:\n",
    "      Lmin: minimum level of refinement  >= 2\n",
    "      Lmax: maximum level of refinement  >= Lmin\n",
    "      N0:   initial number of samples    >  0\n",
    "      eps:  desired accuracy (rms error) >  0\n",
    "\n",
    "      alpha: weak error is  O(2^{-alpha*l})\n",
    "      beta:  variance is    O(2^{-beta*l})\n",
    "      gamma: sample cost is O(2^{gamma*l})  > 0\n",
    "\n",
    "      If alpha, beta are not positive then they will be estimated.\n",
    "\n",
    "      mlmc_fn: the user low-level routine. Its interface is\n",
    "        sums = mlmc_fn(l, N)\n",
    "      with inputs\n",
    "        l = level\n",
    "        N = number of paths\n",
    "      and a numpy array of outputs\n",
    "        sums[0] = sum(Y)\n",
    "        sums[1] = sum(Y**2)\n",
    "      where Y are iid samples with expected value\n",
    "        E[P_0]            on level 0\n",
    "        E[P_l - P_{l-1}]  on level l > 0\n",
    "    \"\"\"\n",
    "\n",
    "    # Check arguments\n",
    "\n",
    "    if Lmin < 2:\n",
    "        raise ValueError(\"Need Lmin >= 2\")\n",
    "    if Lmax < Lmin:\n",
    "        raise ValueError(\"Need Lmax >= Lmin\")\n",
    "    if N0 <= 0 or eps <= 0 or gamma <= 0:\n",
    "        raise ValueError(\"Need N0 > 0, eps > 0, gamma > 0\")\n",
    "\n",
    "    # Initialisation\n",
    "\n",
    "    alpha = max(0, alpha_0)\n",
    "    beta  = max(0, beta_0)\n",
    "\n",
    "    theta = 0.25\n",
    "\n",
    "    L = Lmin\n",
    "\n",
    "    Nl   = numpy.zeros(L+1)\n",
    "    suml = numpy.zeros((2, L+1))\n",
    "    dNl  = N0*numpy.ones(L+1)\n",
    "\n",
    "    while sum(dNl) > 0:\n",
    "\n",
    "        # update sample sums\n",
    "\n",
    "        for l in range(0, L+1):\n",
    "            if dNl[l] > 0:\n",
    "                sums       = mlmc_fn(l, int(dNl[l]))\n",
    "                Nl[l]      = Nl[l] + dNl[l]\n",
    "                suml[0, l] = suml[0, l] + sums[0]\n",
    "                suml[1, l] = suml[1, l] + sums[1]\n",
    "\n",
    "        # compute absolute average and variance\n",
    "\n",
    "        ml = numpy.abs(       suml[0, :]/Nl)\n",
    "        Vl = numpy.maximum(0, suml[1, :]/Nl - ml**2)\n",
    "\n",
    "        # fix to cope with possible zero values for ml and Vl\n",
    "        # (can happen in some applications when there are few samples)\n",
    "\n",
    "        for l in range(3, L+2):\n",
    "            ml[l-1] = max(ml[l-1], 0.5*ml[l-2]/2**alpha)\n",
    "            Vl[l-1] = max(Vl[l-1], 0.5*Vl[l-2]/2**beta)\n",
    "\n",
    "        # use linear regression to estimate alpha, beta if not given\n",
    "        if alpha_0 <= 0:\n",
    "            A = numpy.ones((L, 2)); A[:, 0] = range(1, L+1)\n",
    "            x = numpy.linalg.solve(A, numpy.log2(ml[1:]))\n",
    "            alpha = max(0.5, -x[0])\n",
    "\n",
    "        if beta_0 <= 0:\n",
    "            A = numpy.ones((L, 2)); A[:, 0] = range(1, L+1)\n",
    "            x = numpy.linalg.solve(A, numpy.log2(Vl[1:]))\n",
    "            beta = max(0.5, -x[0])\n",
    "\n",
    "        # set optimal number of additional samples\n",
    "\n",
    "        Cl = 2**(gamma*numpy.arange(0, L+1))\n",
    "        Ns = numpy.ceil( numpy.sqrt(Vl/Cl) * sum(numpy.sqrt(Vl*Cl)) / ((1-theta)*eps**2) )\n",
    "        dNl = numpy.maximum(0, Ns-Nl)\n",
    "\n",
    "        # if (almost) converged, estimate remaining error and decide\n",
    "        # whether a new level is required\n",
    "\n",
    "        if sum(dNl > 0.01*Nl) == 0:\n",
    "            rem = ml[L] / (2.0**alpha - 1.0)\n",
    "\n",
    "            if rem > numpy.sqrt(theta)*eps:\n",
    "                if L == Lmax:\n",
    "                    raise WeakConvergenceFailure(\"Failed to achieve weak convergence\")\n",
    "                else:\n",
    "                    L = L + 1\n",
    "                    Vl = numpy.append(Vl, Vl[-1] / 2.0**beta)\n",
    "                    Nl = numpy.append(Nl, 0.0)\n",
    "                    suml = numpy.column_stack([suml, [0, 0]])\n",
    "\n",
    "                    Cl = 2**(gamma*numpy.arange(0, L+1))\n",
    "                    Ns = numpy.ceil( numpy.sqrt(Vl/Cl) * sum(numpy.sqrt(Vl*Cl)) / ((1-theta)*eps**2) )\n",
    "                    dNl = numpy.maximum(0, Ns-Nl)\n",
    "\n",
    "    # finally, evaluate the multilevel estimator\n",
    "    P = sum(suml[0,:]/Nl)\n",
    "\n",
    "    return (P, Nl)\n",
    "\n",
    "\n",
    "def mlmc_test(mlmc_fn, M, N, L, N0, Eps, Lmin, Lmax, logfile):\n",
    "    \"\"\"\n",
    "    Multilevel Monte Carlo test routine.\n",
    "\n",
    "    mlmc_fn: the user low-level routine. Its interface is\n",
    "      sums = mlmc_fn(l, N)\n",
    "    with inputs\n",
    "      l = level\n",
    "      N = number of paths\n",
    "    and a numpy array of outputs\n",
    "      sums[0] = sum(Pf-Pc)\n",
    "      sums[1] = sum((Pf-Pc)**2)\n",
    "      sums[2] = sum((Pf-Pc)**3)\n",
    "      sums[3] = sum((Pf-Pc)**4)\n",
    "      sums[4] = sum(Pf)\n",
    "      sums[5] = sum(Pf**2)\n",
    "\n",
    "    M: refinement cost factor (2**gamma in general MLMC theorem)\n",
    "\n",
    "    N: number of samples for convergence tests\n",
    "    L: number of levels for convergence tests\n",
    "\n",
    "    N0: initial number of samples for MLMC calculations\n",
    "    Eps: desired accuracy array for MLMC calculations\n",
    "    \"\"\"\n",
    "\n",
    "    # First, convergence tests\n",
    "\n",
    "    write(logfile, \"\\n\")\n",
    "    write(logfile, \"**********************************************************\\n\")\n",
    "    write(logfile, \"*** Convergence tests, kurtosis, telescoping sum check ***\\n\")\n",
    "    write(logfile, \"**********************************************************\\n\")\n",
    "    write(logfile, \"\\n l   ave(Pf-Pc)    ave(Pf)   var(Pf-Pc)    var(Pf)\")\n",
    "    write(logfile, \"    kurtosis     check \\n-------------------------\")\n",
    "    write(logfile, \"--------------------------------------------------\\n\")\n",
    "\n",
    "    del1 = []\n",
    "    del2 = []\n",
    "    var1 = []\n",
    "    var2 = []\n",
    "    kur1 = []\n",
    "    chk1 = []\n",
    "    cost = []\n",
    "\n",
    "    for l in range(0, L+1):\n",
    "        tic = timeit.default_timer()\n",
    "        sums = mlmc_fn(l, N)\n",
    "        toc = timeit.default_timer()\n",
    "        cost.append(toc - tic)\n",
    "        sums = sums/N\n",
    "\n",
    "        if l == 0:\n",
    "            kurt = 0.0\n",
    "        else:\n",
    "            kurt = (     sums[3]\n",
    "                     - 4*sums[2]*sums[0]\n",
    "                     + 6*sums[1]*sums[0]**2\n",
    "                     - 3*sums[0]*sums[0]**3 ) / (sums[1]-sums[0]**2)**2\n",
    "\n",
    "        del1.append(sums[0])\n",
    "        del2.append(sums[4])\n",
    "        var1.append(sums[1]-sums[0]**2)\n",
    "        var2.append(max(sums[5]-sums[4]**2, 1.0e-10)) # fix for cases with var = 0\n",
    "        kur1.append(kurt)\n",
    "\n",
    "        if l == 0:\n",
    "            check = 0\n",
    "        else:\n",
    "            check =          abs(       del1[l]  +      del2[l-1]  -      del2[l])\n",
    "            check = check / ( 3.0*(sqrt(var1[l]) + sqrt(var2[l-1]) + sqrt(var2[l]) )/sqrt(N))\n",
    "        chk1.append(check)\n",
    "\n",
    "        write(logfile, \"%2d   %8.4e  %8.4e  %8.4e  %8.4e  %8.4e  %8.4e \\n\" % \\\n",
    "                      (l, del1[l], del2[l], var1[l], var2[l], kur1[l], chk1[l]))\n",
    "\n",
    "    if kur1[-1] > 100.0:\n",
    "        write(logfile, \"\\n WARNING: kurtosis on finest level = %f \\n\" % kur1[-1]);\n",
    "        write(logfile, \" indicates MLMC correction dominated by a few rare paths; \\n\");\n",
    "        write(logfile, \" for information on the connection to variance of sample variances,\\n\");\n",
    "        write(logfile, \" see http://mathworld.wolfram.com/SampleVarianceDistribution.html\\n\\n\");\n",
    "\n",
    "    if max(chk1) > 1.0:\n",
    "        write(logfile, \"\\n WARNING: maximum consistency error = %f \\n\" % max(chk1))\n",
    "        write(logfile, \" indicates identity E[Pf-Pc] = E[Pf] - E[Pc] not satisfied \\n\\n\")\n",
    "\n",
    "    L1 = int(numpy.ceil(0.4*L));\n",
    "    L2 = L+1;\n",
    "    pa    = numpy.polyfit(range(L1+1, L2+1), numpy.log2(numpy.abs(del1[L1:L2])), 1);  alpha = -pa[0];\n",
    "    pb    = numpy.polyfit(range(L1+1, L2+1), numpy.log2(numpy.abs(var1[L1:L2])), 1);  beta  = -pb[0];\n",
    "    gamma = numpy.log2(cost[-1]/cost[-2]);\n",
    "\n",
    "    write(logfile, \"\\n******************************************************\\n\");\n",
    "    write(logfile, \"*** Linear regression estimates of MLMC parameters ***\\n\");\n",
    "    write(logfile, \"******************************************************\\n\");\n",
    "    write(logfile, \"\\n alpha = %f  (exponent for MLMC weak convergence)\\n\" % alpha);\n",
    "    write(logfile, \" beta  = %f  (exponent for MLMC variance) \\n\" % beta);\n",
    "    write(logfile, \" gamma = %f  (exponent for MLMC cost) \\n\" % gamma);\n",
    "\n",
    "    # Second, MLMC complexity tests\n",
    "\n",
    "    write(logfile, \"\\n\");\n",
    "    write(logfile, \"***************************** \\n\");\n",
    "    write(logfile, \"*** MLMC complexity tests *** \\n\");\n",
    "    write(logfile, \"***************************** \\n\\n\");\n",
    "    write(logfile, \"  eps   mlmc_cost   std_cost  savings     N_l \\n\");\n",
    "    write(logfile, \"----------------------------------------------- \\n\");\n",
    "\n",
    "    gamma = numpy.log2(M)\n",
    "    theta = 0.25\n",
    "\n",
    "    for eps in Eps:\n",
    "       (P, Nl) = mlmc(Lmin, Lmax, N0, eps, mlmc_fn, alpha, beta, gamma)\n",
    "       l = len(Nl) - 1\n",
    "       mlmc_cost = (1 + 1.0/M)*sum(Nl * M**numpy.arange(0, l+1))\n",
    "       std_cost  = sum(var2[-1]*M**numpy.arange(0, l+1))/((1.0 -theta)*eps**2)\n",
    "\n",
    "       write(logfile, \"%.4f  %.3e  %.3e  %7.2f \" % (eps, mlmc_cost, std_cost, std_cost/mlmc_cost))\n",
    "       write(logfile, \" \".join([\"%9d\" % n for n in Nl]))\n",
    "       write(logfile, \"\\n\")\n",
    "\n",
    "    write(logfile, \"\\n\")\n",
    "\n",
    "def write(logfile, msg):\n",
    "    \"\"\"\n",
    "    Write to both sys.stdout and to a logfile.\n",
    "    \"\"\"\n",
    "    logfile.write(msg)\n",
    "    sys.stdout.write(msg)\n",
    "    \n",
    "def mlmc_plot(filename, nvert):\n",
    "\n",
    "    file = open(filename, \"r\")\n",
    "\n",
    "    # Declare lists for data\n",
    "    del1 = []\n",
    "    del2 = []\n",
    "    var1 = []\n",
    "    var2 = []\n",
    "    kur1 = []\n",
    "    chk1 = []\n",
    "    l    = []\n",
    "\n",
    "    epss = []\n",
    "    mlmc_cost = []\n",
    "    std_cost = []\n",
    "    Ns = []\n",
    "\n",
    "    for line in file:\n",
    "        # Recognise convergence test lines from the fact that line[1] is an integer\n",
    "        if line[0] == ' ' and '0' <= line[1] <= '9':\n",
    "            splitline = [float(x) for x in line.split()]\n",
    "            l.append(splitline[0])\n",
    "            del1.append(splitline[1])\n",
    "            del2.append(splitline[2])\n",
    "            var1.append(splitline[3])\n",
    "            var2.append(splitline[4])\n",
    "            kur1.append(splitline[5])\n",
    "            chk1.append(splitline[6])\n",
    "\n",
    "        # Recognise MLMC complexity test lines from the fact that line[0] is an integer\n",
    "        if '0' <= line[0] <= '9':\n",
    "            splitline = [float(x) for x in line.split()]\n",
    "            epss.append(splitline[0])\n",
    "            mlmc_cost.append(splitline[1])\n",
    "            std_cost.append(splitline[2])\n",
    "            Ns.append(splitline[4:])\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "\n",
    "    plt.subplot(nvert, 2, 1)\n",
    "    plt.plot(l,     numpy.log2(var2),     '*-',  label=r'$P_l$')\n",
    "    plt.plot(l[1:], numpy.log2(var1[1:]), '*--', label=r'$P_l - P_{l-1}$')\n",
    "    plt.xlabel('level $l$')\n",
    "    plt.ylabel(r'$\\mathrm{log}_2(\\mathrm{variance})$')\n",
    "    plt.legend(loc='lower left', fontsize='x-small')\n",
    "\n",
    "    plt.subplot(nvert, 2, 2)\n",
    "    plt.plot(l,     numpy.log2(numpy.abs(del2)),     '*-',  label=r'$P_l$')\n",
    "    plt.plot(l[1:], numpy.log2(numpy.abs(del1[1:])), '*--', label=r'$P_l - P_{l-1}$')\n",
    "    plt.xlabel('level $l$')\n",
    "    plt.ylabel(r'$\\mathrm{log}_2(|\\mathrm{mean}|)$')\n",
    "    plt.legend(loc='lower left', fontsize='x-small')\n",
    "\n",
    "    if nvert == 3:\n",
    "        plt.subplot(nvert, 2, 3)\n",
    "        plt.plot(l[1:], chk1[1:], '*--')\n",
    "        plt.xlabel('level $l$')\n",
    "        plt.ylabel(r'consistency check')\n",
    "        axis = plt.axis(); plt.axis([0, max(l), axis[2], axis[3]])\n",
    "\n",
    "        plt.subplot(nvert, 2, 4)\n",
    "        plt.plot(l[1:], kur1[1:], '*--')\n",
    "        plt.xlabel('level $l$')\n",
    "        plt.ylabel(r'kurtosis')\n",
    "        axis = plt.axis(); plt.axis([0, max(l), axis[2], axis[3]])\n",
    "\n",
    "    styles = ['o--', 'x--', 'd--', '*--', 's--']\n",
    "    plt.subplot(nvert, 2, 2*nvert-1)\n",
    "    for (eps, N, style) in zip(epss, Ns, styles):\n",
    "        plt.semilogy(N, style, label=eps)\n",
    "    plt.xlabel('level $l$')\n",
    "    plt.ylabel('$N_l$')\n",
    "    plt.legend(loc='upper right', frameon=True, fontsize='x-small')\n",
    "\n",
    "    eps = numpy.array(epss)\n",
    "    std_cost = numpy.array(std_cost)\n",
    "    mlmc_cost = numpy.array(mlmc_cost)\n",
    "    plt.subplot(nvert, 2, 2*nvert)\n",
    "    plt.loglog(eps, eps**2 * std_cost,  '*-',  label='std MC')\n",
    "    plt.loglog(eps, eps**2 * mlmc_cost, '*--', label='MLMC')\n",
    "    plt.xlabel(r'accuracy $\\epsilon$')\n",
    "    plt.ylabel(r'$\\epsilon^2$ cost')\n",
    "    plt.legend(fontsize='x-small')\n",
    "    axis = plt.axis(); plt.axis([min(eps), max(eps), axis[2], axis[3]])\n",
    "\n",
    "    plt.subplots_adjust(wspace=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our SDE \n",
    "\\begin{align}\n",
    "dX_t = -X_tdt + dW_t\n",
    "\\end{align}\n",
    "with initial condition $X_0 = 0$ has explicit solution\n",
    "\\begin{align}\n",
    "X_t = \\exp(-t)\\int_0^t \\exp(s)dW_s.\n",
    "\\end{align}\n",
    "Thus\n",
    "\\begin{align}\n",
    "X_t \\sim \\mathcal{N} \\left( 0, \\frac{1}{2}\\left(1- \\exp(-2t) \\right) \\right).\n",
    "\\end{align}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sde_mlmc(T, n0, M, N, l):\n",
    "    \n",
    "    #lbda = 2\n",
    "    \n",
    "    T_new = T\n",
    "    #T_new = T * (l+1) * np.log(2) / lbda\n",
    "    \n",
    "    n = n0 * (M ** l)\n",
    "    h = T_new / n\n",
    "\n",
    "    nf = n0 * (M ** l)\n",
    "    hf = T_new / nf\n",
    "\n",
    "    nc = max(nf/M, 1)\n",
    "    hc = T_new / nc\n",
    "\n",
    "    sums = numpy.zeros(6)\n",
    "\n",
    "    for N1 in range(1, N+1, 10000):\n",
    "        N2 = min(10000, N - N1 + 1)\n",
    "\n",
    "        Xf = np.zeros(N2)\n",
    "        Xc = np.zeros(N2)\n",
    "\n",
    "        if l == 0:\n",
    "            dWf = sqrt(hf) * rd.randn(1, N2)\n",
    "            Xf[:] = (1 - hf)*Xf + dWf\n",
    "            \n",
    "        else:\n",
    "            for n in range(int(nc)):\n",
    "                dWc = np.zeros((1, N2))\n",
    "\n",
    "                for m in range(M):\n",
    "                    dWf = sqrt(hf) * rd.randn(1, N2)\n",
    "                    dWc[:] = dWc + dWf\n",
    "                    Xf[:] = (1  - hf)*Xf + dWf\n",
    "\n",
    "                Xc[:] = (1  - hc)*Xc + dWc\n",
    "\n",
    "        Pf = Xf * Xf\n",
    "        Pc = Xc * Xc\n",
    "\n",
    "        sums += np.array([np.sum(Pf - Pc),\n",
    "                             np.sum((Pf - Pc)**2),\n",
    "                             np.sum((Pf - Pc)**3),\n",
    "                             np.sum((Pf - Pc)**4),\n",
    "                             np.sum(Pf),\n",
    "                             np.sum(Pf**2)])\n",
    "    #return np.array(sums)\n",
    "    return numpy.array(sums)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.48833257665516755, array([138888.,  55609.,  13107.,   3980.,   1030.]))\n"
     ]
    }
   ],
   "source": [
    "T = 10 # terminal time\n",
    "n0 = 9 # initial number of time steps\n",
    "M = 3\n",
    "eps = 0.01\n",
    "N0 = 10\n",
    "Lmin = 2\n",
    "Lmax = 100\n",
    "\n",
    "alpha = np.log2(M)\n",
    "beta = np.log2(M)\n",
    "gamma = np.log2(M)\n",
    "\n",
    "def mlmc_fn(l, N):\n",
    "    \"\"\"a wrapper for the tau_leaping_mlmc method\"\"\"\n",
    "    return sde_mlmc(T, n0, M, N, l)\n",
    "\n",
    "print(mlmc(Lmin, Lmax, N0, eps, mlmc_fn, alpha, beta, gamma))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
